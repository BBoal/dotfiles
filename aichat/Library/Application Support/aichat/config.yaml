model: openai:gpt-4o-mini
# model: ollama:llama3.2:3b-instruct-q8_0
save: true

highlight: true
light_theme: true

clients:
  - type: openai
  - type: claude
  - type: openai-compatible
    name: ollama
    api_base: http://localhost:11434/v1
  - type: openai-compatible
    name: github
    api_base: https://models.inference.ai.azure.com
  - type: openai-compatible
    name: openrouter
    api_base: https://openrouter.ai/api/v1
  - type: openai-compatible
    name: groq
    api_base: https://api.groq.com/openai/v1

# rag_embedding_model: null # TODO: how to use local model

document_loaders:
  pdf: "pdftotext $1 -"
  docx: "pandoc --to plain $1"
