model: openai:gpt-4o-mini
# model: ollama:llama3.2:3b-instruct-q8_0
save: true

highlight: true
light_theme: true

clients:
  - type: openai
  - type: claude
  - type: openai-compatible
    name: ollama
    api_base: http://localhost:11434/v1
    models:
      - name: llama3.2
        model: llama3.2:latest
        max_input_tokens: 131072
      - name: llama3.2-instruct-1b
        model: llama3.2:1b-instruct-fp16
        max_input_tokens: 131072
      - name: llama3.2-instruct-3b
        model: llama3.2:3b-instruct-fp16
        max_input_tokens: 131072
      - name: llama3.2-instruct-3b-q8
        model: llama3.2:3b-instruct-q8_0
        max_input_tokens: 131072

# rag_embedding_model: null # TODO: how to use local model

document_loaders:
  pdf: "pdftotext $1 -"
  docx: "pandoc --to plain $1"
